defaults:
  - default_dataset.yaml

exp_name: vggt_1d_7_datasets
img_size: 256
num_workers: 1
seed_value: 42
accum_steps: 1   # We did not use gradient accumulation in our training, while if you suffer from OOM, you can try to use it.
patch_size: 16
val_epoch_freq: 5
max_img_per_gpu: 200

limit_train_batches: 400
limit_val_batches: 400


data:
  # The code for data still looks too complicated. I should refactor this again (do I have time?...)
  train:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    max_img_per_gpu: ${max_img_per_gpu}
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: False
      repeat_batch: False
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        # # - _target_: data.datasets.vkitti.VKittiDataset
        # #   split: train
        # #   VKitti_DIR: /home/solution/Documents/Projects/Dataset/vkitti
        # #   len_train: 100000
        # #   expand_ratio: 8 

        # - _target_: data.datasets.vkitti.VKittiDataset
        #   split: train
        #   VKitti_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/vkitti
        #   len_train: 100000
        #   expand_ratio: 8 

        # # MVS Synth Error
        # # - _target_: data.datasets.MVSSynth.MVSSynthDataset
        # #   split: train
        # #   MVSSynth_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/MVS-Synth/GTAV_720
        # #   len_train: 100000
        # #   expand_ratio: 8 

        # # ASE
        # - _target_: data.datasets.ASE.ASEDataset
        #   split: train
        #   ASE_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/ASE
        #   len_train: 10000
        #   expand_ratio: 8

        # # DL3DV
        # - _target_: data.datasets.DL3DV.DL3DVDataset
        #   split: train
        #   DL3DV_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/DL3DV-ALL-960P/DL3DV
        #   len_train: 100000
        #   expand_ratio: 8

        # # Mapillary
        # - _target_: data.datasets.mapillary.MapillaryDataset
        #   split: train
        #   MAPILLARY_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/Mapillary
        #   len_train: 100000
        #   expand_ratio: 8

        # # Omnidata HyperSim
        # # - _target_: data.datasets.Omnidata.OmniDataset
        # #   split: train
        # #   CAMERA_POSE_ROOT: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/Omnidata/omnidata_starter_dataset/camera_pose/hypersim
        # #   len_train: 100000
        # #   expand_ratio: 8

        # # Omnidata Replica
        # - _target_: data.datasets.Omnidata.OmniDataset
        #   split: train
        #   CAMERA_POSE_ROOT: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/Omnidata/omnidata_starter_dataset/camera_pose/replica
        #   len_train: 100000
        #   expand_ratio: 8

        # # WildRGBD
        # - _target_: data.datasets.wildrgbd.WildRGBDDataset
        #   split: train
        #   WILDRGBD_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/WildRGB-D
        #   len_train: 100000
        #   expand_ratio: 8


        # # ADT Slow
        # # - _target_: data.datasets.ADT.ADTDataset
        # #   split: train
        # #   ADT_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/ADT
        # #   len_train: 100000
        # #   expand_ratio: 8


        # # Omnidata Taskonomy Slow
        # # - _target_: data.datasets.Omnidata.OmniDataset
        # #   split: train
        # #   CAMERA_POSE_ROOT: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/Omnidata/omnidata_starter_dataset/camera_pose/taskonomy
        # #   len_train: 100000
        # #   expand_ratio: 8


        # # MegaDepth
        # - _target_: data.datasets.megadepth.MegaDepthDataset
        #   split: train
        #   MEGADEPTH_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/MegaDepth/phoenix/S6/zl548/MegaDepth_v1
        #   len_train: 100000
        #   expand_ratio: 8
      
        # # # ScanNetv2 Not Complete
        # # - _target_: data.datasets.scanNetv2.ScanNetv2
        # #   split: train
        # #   ScanNetv2_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/vlm_visual_odom/ScanNet/decoded/test
        # #   len_train: 100000
        # #   expand_ratio: 8

        # # BlendedMVS
        # - _target_: data.datasets.blendedmvs.BlendedMVSDataset
        #   split: train
        #   BLENDED_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/BlendedMVS/BlendedMVS
        #   len_train: 100000
        #   expand_ratio: 8

        # CO3D
        - _target_: data.datasets.co3d.Co3dDataset
          split: train
          CO3D_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/co3d
          CO3D_ANNOTATION_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/co3d_anno
          # len_train: 100000
  val:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    max_img_per_gpu: ${max_img_per_gpu}
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: False
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        # - _target_: data.datasets.vkitti.VKittiDataset
        #   split: train
        #   VKitti_DIR: /home/solution/Documents/Projects/Dataset/vkitti
        #   len_train: 10
        #   expand_ratio: 8 
        - _target_: data.datasets.co3d.Co3dDataset
          split: test
          CO3D_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/co3d
          CO3D_ANNOTATION_DIR: /lustre/fsw/portfolios/nvr/projects/nvr_av_verifvalid/users/ymingli/datasets/co3d_anno


logging:
  log_dir: logs
  log_visuals: False
  log_freq: 1
  log_level_primary: DEBUG
  log_level_secondary: WARNING
  all_ranks: False
  tensorboard_writer:
    _target_: train_utils.tb_writer.TensorBoardLogger
    path: ${logging.log_dir}/tensorboard
  scalar_keys_to_log:
    train:
      keys_to_log:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth
    val:
      keys_to_log:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth



checkpoint:
  save_dir: logs/${exp_name}/ckpts
  save_freq: 1
  # resume_pretrained: False
  resume_checkpoint_path: /lustre/fsw/portfolios/nvr/users/ymingli/projects/VideoActionModel/Token/sparse_tokenizer/tokenizer_titok_l32.bin
  strict: False


loss:
  _target_: loss.MultitaskLoss
  camera: 
    weight: 5.0
    loss_type: "l1" # The paper uses smooth l1 loss, but we found l1 loss is more stable than smooth l1 and l2 loss.  
  depth: null
    # weight: 1.0
    # gradient_loss_fn: "grad" 
    # valid_range: 0.98
  point: null
  # If you want to enable point, use the following config
  # point: 
  #   weight: 1.0
  #   gradient_loss_fn: "normal" 
  #   valid_range: 0.98
  track: null   




optim:
  param_group_modifiers: False

  optimizer:
    _target_: torch.optim.AdamW
    lr: 5e-5
    weight_decay: 0.05

  frozen_module_names: null
      # - "*aggregator*"  # example, freeze the aggregator


  amp:
    enabled: True
    amp_dtype: bfloat16
  gradient_clip:
    _target_: train_utils.gradient_clip.GradientClipper
    configs:
      - module_name: ["aggregator"]
        max_norm: 1.0   # feel free to reduce this if you see instabilities
        norm_type: 2
      - module_name: ["depth"]
        max_norm: 1.0   # feel free to reduce this if you see instabilities
        norm_type: 2
      - module_name: ["camera"]
        max_norm: 1.0   # feel free to reduce this if you see instabilities
        norm_type: 2
  options:
    lr:
      - scheduler:
          _target_: fvcore.common.param_scheduler.CompositeParamScheduler
          schedulers:
            - _target_: fvcore.common.param_scheduler.LinearParamScheduler
              start_value: 1e-8
              end_value: 5e-5
            - _target_: fvcore.common.param_scheduler.CosineParamScheduler
              start_value: 5e-5
              end_value: 1e-8
          lengths: [0.05, 0.95]
          interval_scaling: ['rescaled', 'rescaled']
    weight_decay:
      - scheduler:
          _target_: fvcore.common.param_scheduler.ConstantParamScheduler
          value: 0.05




max_epochs: 20

model:
  _target_: vggt.models.vggt.VGGT
  img_size: ${img_size}
  patch_size: ${patch_size}
  use_1d: True
  enable_camera: True
  enable_depth: False
  enable_point: False
  enable_track: False


distributed:
  # check https://docs.pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html for options
  backend: nccl
  comms_dtype: None
  find_unused_parameters: False
  timeout_mins: 30
  gradient_as_bucket_view: True  # Less memory used
  bucket_cap_mb: 25
  broadcast_buffers: True

cuda:
    cudnn_deterministic: False
    cudnn_benchmark: False
    allow_tf32: True
